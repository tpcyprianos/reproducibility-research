{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data\n",
    "The Dataset used in these experiments, Facebook Metrics, is available on [Machine Learning Repository](http://archive.ics.uci.edu/ml/datasets/Facebook+metrics). You can also find the related files in this repository, in the directory [/data](../data).\n",
    "\n",
    "## Facebook Metrics Dataset\n",
    "The data is related to posts published during the year of 2014 (from 1st of January to 31st of December) on the Facebook's page of a renowned cosmetics brand. The dataset has 500 instances and 19 attributes.\n",
    "\n",
    "### Describing Attributes\n",
    "The authors published the dataset with original Facebook metrics + data mining outputs. Altough, for these initial experiments, only some attributes were selected, as it will be explained in the section **Attributes Selection** below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Dataset Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('../data/dataset_Facebook.csv', sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Original Dataset Attributes\")\n",
    "#print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Checking the dataset\n",
    "#print(\"Dataset\")\n",
    "#data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Attributes\n",
    "Because the main goal of this step is to index the information in Graph Database, the attributes that represent post's raw data were used. As follows:\n",
    "\n",
    "* Page total likes\n",
    "* Type (Link, Photo, Status, Video)\n",
    "* Category (Action, Product, Inspiration)\n",
    "* Post Month\n",
    "* Post Weekday\n",
    "* Post hour\n",
    "* Paid\n",
    "* comment\n",
    "* like\n",
    "* share"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading dataset\n",
    "In this code, the reading method selects only the targeted attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/dataset_Facebook.csv', sep=\";\", usecols=['Page total likes', 'Type', 'Category', 'Post Month', 'Post Weekday',\n",
    "       'Post Hour', 'Paid', 'comment', 'like', 'share'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding and Removing null values\n",
    "Cleaning data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.isnull().any()\n",
    "\n",
    "def num_missing(x):\n",
    "  return sum(x.isnull())\n",
    "\n",
    "print (\"Missing values per column:\")\n",
    "print (data.apply(num_missing, axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Attributes\n",
    "For indexing the data in Graph Database, other attribues (columns) were added:\n",
    "* Post Id - ID Number for the post\n",
    "* Increase in Likes - How many more likes were accounted for \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating the colunm of Id\n",
    "dataLength = len(data['Page total likes'])\n",
    "\n",
    "dataIndexes = [x for x in range(dataLength)]\n",
    "\n",
    "data['Post id'] = pd.Series(dataIndexes, index=data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Some descriptions of data\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sorting Data\n",
    "For making more sense, it was necessary to perform a descending chronological sort data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataOrderedDescending = data.sort_values(by='Post id', ascending=False)\n",
    "dataOrderedDescending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculating the Increase in Likes\n",
    "The information *Page total likes* is important, but other interesting information to be stored in database is the increase/decrease of likes, meaning how many likes the page had in that day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "listIncreaseLikes = []\n",
    "\n",
    "#\n",
    "currentPageLikes  = dataOrderedDescending['Page total likes'].iloc[0]\n",
    "\n",
    "for i, row in dataOrderedDescending.iterrows():   \n",
    "    dif = int(row['Page total likes']) - currentPageLikes\n",
    "    \n",
    "    listIncreaseLikes.append(dif)\n",
    "    \n",
    "    if (row['Page total likes'] != currentPageLikes):\n",
    "        currentPageLikes = row['Page total likes']\n",
    "    \n",
    "dataOrderedDescending['Increase likes'] = pd.Series(listIncreaseLikes, index=dataOrderedDescending.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Altering category from numbers to values\n",
    "The dataset's category values are numbers (1,2,3), but according paper's authors, the corresponding categories are:\n",
    "* 1 = Action\n",
    "* 2 = Product\n",
    "* 3 = Inspiration\n",
    "\n",
    "So, for being more clear and for indexing data in Graph Database, it is necessary alter the category to its correspond value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categoriesNames = [\"\",\"Action\",\"Product\",\"Inspiration\"]\n",
    "listCategories  = []\n",
    "\n",
    "for i, row in dataOrderedDescending.iterrows():   \n",
    "    listCategories.append((categoriesNames[int(row[\"Category\"])]))\n",
    "    \n",
    "dataOrderedDescending[\"Category\"] = pd.Series(listCategories, index=dataOrderedDescending.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salving Output File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataOrderedDescending.to_csv('..\\data\\dataset_Facebook_processed.csv', \";\", index=False)\n",
    "print(\"File saved: dataset_Facebook_processed.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
